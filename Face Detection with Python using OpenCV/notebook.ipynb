{"cells":[{"source":"# Face Detection with Python using OpenCV\n\nThis tutorial will introduce you to the concept of object detection in Python using OpenCV library and how you can utilize it to perform tasks like Facial detection.","metadata":{},"id":"728beafb-dbf0-4db3-a176-46384224de3e","cell_type":"markdown"},{"source":"## What is Computer Vision?\n\nWe are currently living in an age of AI revolution, marked by impressive advancements in the field of deep learning. In just the past few months, we’ve witnessed applications of artificial intelligence that stunned the world by generating realistic pieces of artwork, passing the bar exam, and writing Python code to create websites.\n\nComputer vision is a deep learning application that lies at the heart of this revolution. It allows computers to derive insight from visual input such as images and video files. Examples of computer vision include face detection, facial recognition, human pose estimation, and obstacle detection.In this tutorial, we will explore how to perform face detection with OpenCV, looking at both still and real-time images. ","metadata":{},"id":"ce60f084-4de9-4c06-871a-d7e9e8161e57","cell_type":"markdown"},{"source":"## Applications of Computer Vision\n\nWhy do we need computer vision when human vision is a relatively trivial task for most humans to accomplish?\n\nWhile it is true that humans can perform visual tasks with ease and require only a few data samples, AI is highly scalable. Computer vision models can process millions of data points when deployed in surveillance and autonomous vehicles. This is a scale that simply cannot be achieved by human vision.\n\nFurthermore, computer vision applications can be integrated into sensors, cameras, and intelligent devices for real-time image processing that involves 24/7 operation. Again, this is an incredibly challenging feat for humans to achieve.\n\nFinally, AI is not susceptible to biases, fatigue, and inattention. While humans may get tired and overlook a security breach, a computer vision application will never falter, thereby reducing the risk of missed incidents.\n\nLet’s look at some real-world applications of computer vision in our daily lives:\n\n### Surveillance\n\nComputer vision applications such as object recognition and pose estimation are often deployed in security devices to automate human surveillance. A pose estimation model, for instance, can track a person’s body language to gauge if they are inciting violence, experiencing a medical emergency, or are about to steal something. These systems can then trigger a notification that alerts the relevant authorities for assistance, decreasing response times and improving public safety.\n\n### Retail\n\nComputer vision models can be deployed in retail outlets to track customers’ eye position, body language, and movement around the store.\n\nThese algorithms can provide retailers with the following insight into user behavior:\n\n- Are there any specific promotions or products that capture people’s attention and draw them into the store?\n- What path do customers typically take when in the store?\n- What type of product placement sparks the most attention?\n- How often do customers engage with promotional materials such as banners and signage?\n\n\nRetailers can then use these insights to improve the store’s marketing strategy and customize product placement to drive sales.\n\n### Autonomous Vehicles\n\nThe field of autonomous driving has benefited tremendously from computer vision technologies. \n\nObject detection models are deployed in vehicles to identify pedestrians, other vehicles, and animals on the road. \n\nComputer vision applications can interpret stop signs and traffic lights, accurately estimate the distance between the vehicle and other objects, and avoid obstacles like potholes to ensure a safe driving experience.","metadata":{},"id":"434b6d09-2cdc-4495-842a-ff6858871db0","cell_type":"markdown"},{"source":"## Introduction to OpenCV\n\nNow that we understand just how useful computer vision applications are, let’s examine a popular tool used to implement them. [OpenCV](https://opencv.org/) is a computer vision library that supports programming languages like Python, C++, and Java.\n\nThe package was initially created by Intel in 1999 and was later made open-source and released to the public.\n\nOpenCV allows developers and non-mathematicians to build computer vision applications easily without having to code them from scratch. The library has over 2,500 algorithms that allow users to perform tasks like face recognition and object detection.\n\nDevelopers and data practitioners at well-established organizations like Google, Microsoft, IBM, and Intel make extensive use of the OpenCV library, which is currently free for commercial use.\n\nIn this article, we will use OpenCV to perform face detection in Python.\n\nBy the end of this tutorial, you will know how to:\n\n- Detect human faces in images with OpenCV in Python\n- Perform real-time face detection in a live stream from a webcam\n- Recognize and label celebrity faces in images\n","metadata":{},"id":"fdccd780-3ed7-498c-ae1c-959295bcda50","cell_type":"markdown"},{"source":"## What is Face Detection?\n\nFace detection involves identifying a person’s face in an image or video. This is done by analyzing the visual input to determine whether a person’s facial features are present.\n\nSince human faces are so diverse, face detection models typically need to be trained on large amounts of input data for them to be accurate. The training dataset must contain a sufficient representation of people who come from different backgrounds, genders, and cultures.\n\nThese algorithms also need to be fed many training samples comprising different lighting, angles, and orientations to make correct predictions in real-world scenarios.\n\nThese nuances make face detection a non-trivial, time-consuming task that requires hours of model training and millions of data samples.\n\nThankfully, the OpenCV package comes with pre-trained models for face detection, which means that we don’t have to train an algorithm from scratch. More specifically, the library employs a machine learning approach called Haar cascade to identify objects in visual data. ","metadata":{},"id":"59f27e02-9e15-4258-90a5-cd3eae59330e","cell_type":"markdown"},{"source":"## OpenCV for Face Detection Tutorial\n\nIn this section, we will learn to apply a popular face detection approach called Haar Cascade for face detection using OpenCV and Python.\n\n### Intro to Haar Cascade Classifiers\n\nThis method was first introduced in the paper [Rapid Object Detection Using a Boosted Cascade of Simple Features](https://www.researchgate.net/publication/3940582_Rapid_Object_Detection_using_a_Boosted_Cascade_of_Simple_Features), written by Paul Viola and Michael Jones.\n\nThe idea behind this technique involves using a cascade of classifiers to detect different features in an image. These classifiers are then combined into one strong classifier that can accurately distinguish between samples that contain a human face from those that don’t.\n\nThe Haar Cascade classifier that is built into OpenCV has already been trained on a large dataset of human faces, so no further training is required. We just need to load the classifier from the library and use it to perform face detection on an input image.\n\n### Installing OpenCV for Python\n\nTo install the OpenCV library, simply open your command prompt or terminal window and run the following command:","metadata":{},"id":"3fb09cf8-c2b9-41da-9951-9ca08e83734e","cell_type":"markdown"},{"source":"!pip install opencv-python","metadata":{},"id":"d87d4569-ad49-4ba3-8119-d38ba9ce4db0","cell_type":"code","execution_count":null,"outputs":[]},{"source":"This command will only work if you already have pip installed on your device. If you’d like to learn more about the pip package manager, you can read our [PIP Python Tutorial](https://www.datacamp.com/tutorial/pip-python-package-manager).\n\n### OpenCV for Face Detection in Images\n\nWe will build a detector to identify the human face in a [photo](https://unsplash.com/photos/rpF3p_RrE9g) from Unsplash. Make sure to save the picture to your working directory and rename it to `input_image` before coding along.\n\n#### Step 1: Import the OpenCV Package\n\nNow, let’s import OpenCV and enter the input image path with the following lines of code:","metadata":{},"id":"1b866c54-eeb6-4036-9597-fb8ba066dde4","cell_type":"markdown"},{"source":"import cv2\n\nimagePath = 'input_image.jpg'","metadata":{},"id":"70537786-c71d-4707-85fe-1250f70d869c","cell_type":"code","execution_count":null,"outputs":[]},{"source":"#### Step 2: Read the Image\n\nThen, we need to read the image with OpenCV’s imread() function:","metadata":{},"id":"36930808-9317-40b0-80f1-cdb50b4418bf","cell_type":"markdown"},{"source":"img = cv2.imread(imagePath)","metadata":{},"id":"20baf603-6081-49c4-af29-5bb1f7d678e5","cell_type":"code","execution_count":null,"outputs":[]},{"source":"This will load the image from the specified file path and return it in the form of a Numpy array. \n\nLet’s print the dimensions of this array:","metadata":{},"id":"9cfa3452-e06b-4589-b43b-31a1bf70b243","cell_type":"markdown"},{"source":"img.shape","metadata":{},"id":"7fc00cc5-e950-4d69-b399-cc2213736868","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Notice that this is a 3-dimensional array. The array’s values represent the picture’s height, width, and channels respectively. Since this is a color image, there are three channels used to depict it - blue, green, and red (BGR). \n\nNote that while the conventional sequence used to represent images is RGB (Red, Blue, Green), the OpenCV library uses the opposite layout (Blue, Green, Red).\n\n#### Step 3: Convert the Image to Grayscale\n\nTo improve computational efficiency, we first need to convert this image to grayscale before performing face detection on it:","metadata":{},"id":"8d1a895c-a92f-4b1d-a8a0-85e56cd7c666","cell_type":"markdown"},{"source":"gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)","metadata":{},"id":"873381c8-0f07-4633-b4fc-6de7c60099a4","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Let’s now examine the dimensions of this grayscale image:","metadata":{},"id":"86d6f719-b5b1-447c-9a28-ebae1e82b761","cell_type":"markdown"},{"source":"gray_image.shape","metadata":{},"id":"5456296f-7069-4352-95e4-510f18b77adb","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Notice that this array only has two values since the image is grayscale and no longer has the third color channel.\n\n#### Step 4: Load the Classifier\n\nLet’s load the pre-trained Haar Cascade classifier that is built into OpenCV:","metadata":{},"id":"a769bde7-0b4d-46b3-bc37-ac5a7b52416e","cell_type":"markdown"},{"source":"face_classifier = cv2.CascadeClassifier(\n    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n)","metadata":{},"id":"b1d497e8-9c47-48db-afc1-c9dc558f9768","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Notice that we are using a file called `haarcascade_frontalface_default.xml`. This classifier is designed specifically for detecting frontal faces in visual input. \n\nOpenCV also provides other pre-trained models to detect different objects within an image - such as a person’s eyes, smile, upper body, and even a vehicle’s license plate. You can learn more about the different classifiers built into OpenCV by examining the library’s [GitHub repository](https://github.com/opencv/opencv/tree/master/data/haarcascades).\n\n#### Step 5: Perform the Face Detection\n\nWe can now perform face detection on the grayscale image using the classifier we just loaded:","metadata":{},"id":"d0ebc51d-1df7-4a52-98b8-cf3ebe8910c5","cell_type":"markdown"},{"source":"face = face_classifier.detectMultiScale(\n    gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)\n)","metadata":{},"id":"255ac5e2-d4ed-4735-aca4-517747e3779b","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Let’s break down the methods and parameters specified in the above code:\n\n- detectMultiScale():\n\n\nThe detectMultiScale() method is used to identify faces of different sizes in the input image.\n\n- `grey_image`:\n\n\nThe first parameter in this method is called `grey_image`, which is the grayscale image we created previously.\n\n- `scaleFactor`:\n\n\nThis parameter is used to scale down the size of the input image to make it easier for the algorithm to detect larger faces. In this case, we have specified a scale factor of 1.1, indicating that we want to reduce the image size by 10%.\n\n- `minNeighbors`:\n\n\nThe cascade classifier applies a sliding window through the image to detect faces in it. You can think of these windows as rectangles. \n\nInitially, the classifier will capture a large number of false positives. These are eliminated using the `minNeighbors` parameter, which specifies the number of neighboring rectangles that need to be identified for an object to be considered a valid detection.\n\nTo summarize, passing a small value like 0 or 1 to this parameter would result in a high number of false positives, whereas a large number could lead to losing out on many true positives.\n\nThe trick here is to find a tradeoff that allows us to eliminate false positives while also accurately identifying true positives.\n\n- `minSize`:\n\n\nFinally, the `minSize` parameter sets the minimum size of the object to be detected. The model will ignore faces that are smaller than the minimum size specified.\n\n#### Step 6: Drawing a Bounding Box\n\nNow that the model has detected the faces within the image, let’s run the following lines of code to create a bounding box around these faces:","metadata":{},"id":"82c6a2b0-9153-4b6c-b694-9382cbd62926","cell_type":"markdown"},{"source":"for (x, y, w, h) in face:\n    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)","metadata":{},"id":"156ecdaf-2751-4132-9e70-5ad23bdd8c85","cell_type":"code","execution_count":null,"outputs":[]},{"source":"The `face` variable is an array with four values: the x and y axis in which the faces were detected, and their width and height. The above code iterates over the identified faces and creates a bounding box that spans across these measurements.\n\nThe parameter `0,255,0` represents the color of the bounding box, which is green, and `4` indicates its thickness.\n\n#### Step 7: Displaying the Image\n\nTo display the image with the detected faces, we first need to convert the image from the BGR format to RGB:","metadata":{},"id":"5955901a-8b7f-44e5-ab89-751dcc4bb3e8","cell_type":"markdown"},{"source":"img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","metadata":{},"id":"34424801-95df-46e2-917d-187871eb4233","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Now, let’s use the Matplotlib library to display the image:","metadata":{},"id":"d304941c-29f0-4bd4-be47-50ce9dbb7d3a","cell_type":"markdown"},{"source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,10))\nplt.imshow(img_rgb)\nplt.axis('off')\nplt.show()","metadata":{},"id":"0392350e-db9c-42df-aae1-7faf4a45f37c","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Great!\n\nThe model has successfully detected the human face in this image and created a bounding box around it. ","metadata":{},"id":"bfb81edb-2822-415d-b1c1-b8900ae2ab9d","cell_type":"markdown"},{"source":"### Real-Time Face Detection with OpenCV\n\n**NOTE: The following section does not work in DataCamp Workspace since it's not possible to access the webcam feed**\n\nNow that we have successfully performed face detection on a static image with OpenCV, let’s see how to do the same on a live video stream. \n\n#### Step 1: Pre-Requisites\n\nFirst, let’s go ahead and import the OpenCV library and load the Haar Cascade model just like we did in the previous section. You can skip this block of code if you already ran it previously:","metadata":{},"id":"39f278c3-70ad-4e0b-af6e-b2e25b5cbfd0","cell_type":"markdown"},{"source":"import cv2\n\nface_classifier = cv2.CascadeClassifier(\n    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n)","metadata":{},"id":"667696a9-68c3-471a-a74e-f537d5a09132","cell_type":"code","execution_count":null,"outputs":[]},{"source":"#### Step 2: Access the Webcam\n\nNow, we need to access our device’s camera to read a live stream of video data. This can be done with the following code:","metadata":{},"id":"3bd48656-19ef-4271-a70e-593d7ff9f2a0","cell_type":"markdown"},{"source":"video_capture = cv2.VideoCapture(0)","metadata":{},"id":"cbd0c162-8327-4cfa-a5ab-32cc84e16224","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Notice that we have passed the parameter `0` to the VideoCapture() function. This tells OpenCV to use the default camera on our device. If you have multiple cameras attached to your device, you can change this parameter value accordingly.\n\n#### Step 3: Identifying Faces in the Video Stream\n\nNow, let’s create a function to detect faces in the video stream and draw a bounding box around them:","metadata":{},"id":"1e1b07c1-b953-4428-adf1-7fbcb787be81","cell_type":"markdown"},{"source":"def detect_bounding_box(vid):\n    gray_image = cv2.cvtColor(vid, cv2.COLOR_BGR2GRAY)\n    faces = face_classifier.detectMultiScale(gray_image, 1.1, 5, minSize=(40, 40))\n    for (x, y, w, h) in faces:\n        cv2.rectangle(vid, (x, y), (x + w, y + h), (0, 255, 0), 4)\n    return faces","metadata":{},"id":"355bd511-89f7-4688-b42e-1e6d9e06881e","cell_type":"code","execution_count":null,"outputs":[]},{"source":"The `detect_bounding_box` function takes the video frame as input.\n\nIn this function, we are using the same codes as we did earlier to convert the frame into grayscale before performing face detection.\n\nThen, we are also detecting the face in this image using the same parameter values for `scaleFactor`, `minNeighbors`, and `minSize` as we did previously.\n\nFinally, we draw a green bounding box of thickness `4` around the frame.\n\n#### Step 4: Creating a Loop for Real-Time Face Detection\n\nNow, we need to create an indefinite while loop that will capture the video frame from our webcam and apply the face detection function to it:","metadata":{},"id":"64ecb7c5-08db-4215-8b39-3eac6543c64f","cell_type":"markdown"},{"source":"while True:\n\n    result, video_frame = video_capture.read()  # read frames from the video\n    if result is False:\n        break  # terminate the loop if the frame is not read successfully\n\n    faces = detect_bounding_box(\n        video_frame\n    )  # apply the function we created to the video frame\n\n    cv2.imshow(\n        \"My Face Detection Project\", video_frame\n    )  # display the processed frame in a window named \"My Face Detection Project\"\n\n    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n        break\n\nvideo_capture.release()\ncv2.destroyAllWindows()","metadata":{},"id":"2ba09c72-2f85-4f01-bbab-21851f8e1d8c","cell_type":"code","execution_count":null,"outputs":[]},{"source":"After running the above code, you should see a window called `My Face Detection Project` appear on the screen:\n\n\n\nThe algorithm should track your face and create a green bounding box around it regardless of where you move within the frame.\n\nIn the frame above, the model recognizes my face and my picture on the driving license I’m holding up.\n\nYou can also test the efficacy of this model by holding up multiple pictures or by getting different people to stand at various angles behind the camera. The model should be able to identify all human faces in different backgrounds or lighting settings.\n\nIf you’d like to exit the program, you can press the “q” key on your keyboard to break out of the loop.\n\n## Face Detection with OpenCV - Next Steps\n\nNow that you have learned to successfully detect human faces in both images and real-time videos using the OpenCV library, here are some steps you can take to bring your knowledge to the next level:\n\n### Create Your Own Project\n\nYou can use the code provided in this tutorial as a starting point for your own face detection project.\n\nOne way to expand this project is to identify human faces in different types of input data, such as PDF files or surveillance images. You can even set up a security camera of your own and perform face detection on the data it captures in real-time.\n\nAlso, you can create a face detection model on large datasets or go a step further and perform tasks like detecting whether a person is wearing masks in image datasets.\n\nThe [Face Detection in Images](https://www.kaggle.com/datasets/dataturks/face-detection-in-images/code) and [Face Mask Detection](https://www.kaggle.com/datasets/andrewmvd/face-mask-detection) datasets on Kaggle are good starting points for a portfolio project in this area.\n\n### Build a Facial Recognition Model\n\nWhile face detection is used to detect a human face in visual input, facial recognition goes a step further. This technology is used to verify a person’s identity by matching their face against an existing database.\n\nYou can attempt to build a facial recognition model that identifies a specific face (maybe even yours) amongst a crowd of other people. \n\nThis task will be slightly more challenging than face detection since the model must be trained on many data samples before it can distinguish between people.\n\nBefore building a face recognition model, you might also need to perform pre-processing techniques such as noise reduction and image transformation. \n\nIf these concepts sound foreign to you, don’t fret! You can learn all about image processing by taking our [Image Processing in Python](https://www.datacamp.com/courses/image-processing-in-python) course.\n\n### Gain Domain Expertise\n\nImage and video processing have applications across a wide range of sectors, including security, retail, healthcare, and manufacturing.\n\nIf you’d like to get a job as a computer vision specialist, you first need to understand the types of data used in these industries. Domain expertise will make it easier for you to label, transform, and train datasets in real-world scenarios.\n\nTo get started, you can take our [Biomedical Image Analysis in Python](https://www.datacamp.com/courses/biomedical-image-analysis-in-python) course. This program will teach you how to process CT-scan images, segment a cardiac MRI time series, and determine whether Alzheimer’s disease changes brain structure. \n\nThese concepts will equip you with the skills necessary to enter the field of biomedical imaging.","metadata":{},"id":"08278873-754c-45bc-8856-9fcf3418ac07","cell_type":"markdown"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}