{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is Data Augmentation?\n",
        "\n",
        "Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data. It includes making minor changes to the dataset or using deep learning to generate new data points.  \n",
        "\n",
        "Augmented vs. Synthetic data\n",
        "\n",
        "Augmented data is driven from original data with some minor changes. In the case of image augmentation, we make geometric and color space transformations (flipping, resizing, cropping, brightness, contrast) to increase the size and diversity of the training set.\n",
        "\n",
        "Synthetic data is generated artificially without using the original dataset. It often uses DNNs (Deep Neural Networks) and GANs (Generative Adversarial Networks) to generate synthetic data.\n",
        "\n",
        "Note: the augmentation techniques are not limited to images. You can augment audio, video, text, and other types of data too.\n",
        "\n"
      ],
      "metadata": {
        "id": "-lI-AMoY8N2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitations of Data Augmentation\n",
        "\n",
        "The biases in the original dataset persist in the augmented data.\n",
        "Quality assurance for data augmentation is expensive.\n",
        "Research and development are required to build a system with advanced applications. For example, generating high-resolution images using GANs can be challenging.\n",
        "Finding an effective data augmentation approach can be challenging.\n",
        "Data Augmentation Techniques\n",
        "\n",
        "In this section, we will learn about audio, text, image, and advanced data augmentation techniques.\n",
        "\n",
        "Audio Data Augmentation\n",
        "\n",
        "Noise injection: add gaussian or random noise to the audio dataset to improve the model performance.\n",
        "Shifting: shift audio left (fast forward) or right with random seconds.\n",
        "Changing the speed: stretches times series by a fixed rate.\n",
        "Changing the pitch: randomly change the pitch of the audio.\n",
        "Text Data Augmentation\n",
        "\n",
        "Word or sentence shuffling: randomly changing the position of a word or sentence.\n",
        "Word replacement: replace words with synonyms.\n",
        "Syntax-tree manipulation: paraphrase the sentence using the same word.\n",
        "Random word insertion: inserts words at random.\n",
        "Random word deletion: deletes words at random.\n",
        "Image Augmentation\n",
        "\n",
        "Learn more about image transformation and manipulation with hands-on exercises in our Image Processing with Python skill track.\n",
        "\n",
        "Geometric transformations: randomly flip, crop, rotate, stretch, and zoom images. You need to be careful about applying multiple transformations on the same images, as this can reduce model performance.\n",
        "Color space transformations: randomly change RGB color channels, contrast, and brightness.\n",
        "Kernel filters: randomly change the sharpness or blurring of the image.\n",
        "Random erasing: delete some part of the initial image.\n",
        "Mixing images: blending and mixing multiple images.\n",
        "Advanced Techniques\n",
        "\n",
        "Generative adversarial networks (GANs): used to generate new data points or images. It does not require existing data to generate synthetic data.\n",
        "Neural Style Transfer: a series of convolutional layers trained to deconstruct images and separate context and style.\n"
      ],
      "metadata": {
        "id": "UzDpj8xZ8UPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from keras import layers\n",
        "import keras"
      ],
      "metadata": {
        "id": "CFvKdJDq8bFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "metadata": {
        "id": "FIiPbZ-58hyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = metadata.features['label'].num_classes\n",
        "print(num_classes)"
      ],
      "metadata": {
        "id": "k_KUSAW38kYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_label_name = metadata.features['label'].int2str\n",
        "train_iter = iter(train_ds)\n",
        "fig = plt.figure(figsize=(7, 8))\n",
        "for x in range(4):\n",
        "  image, label = next(train_iter)\n",
        "  fig.add_subplot(1, 4, x+1)\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title(get_label_name(label));"
      ],
      "metadata": {
        "id": "OWitxPH58mnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 180\n",
        "\n",
        "resize_and_rescale = keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "result = resize_and_rescale(image)\n",
        "plt.axis('off')\n",
        "plt.imshow(result);"
      ],
      "metadata": {
        "id": "70VNl7Re80Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.4),\n",
        "])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 7))\n",
        "for i in range(6):\n",
        "  augmented_image = data_augmentation(image)\n",
        "  ax = plt.subplot(2, 3, i + 1)\n",
        "  plt.imshow(augmented_image.numpy()/255)\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "PT4SmA5v822x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Directly adding to the model layer\n",
        "\n",
        "There are two ways to apply augmentation to the images. The first method is by directly adding the augmentation layers to the model."
      ],
      "metadata": {
        "id": "65TqaGTN8_f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "  # Add the preprocessing layers you created earlier.\n",
        "  resize_and_rescale,\n",
        "  data_augmentation,\n",
        "  # Add the model layers\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "btKjK6am9A9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
      ],
      "metadata": {
        "id": "8jG8IjbB9ETm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  # Resize and rescale all datasets.\n",
        "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y),\n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Batch all datasets.\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  # Use data augmentation only on the training set.\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Use buffered prefetching on all datasets.\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
        "val_ds = prepare(val_ds)\n",
        "test_ds = prepare(test_ds)"
      ],
      "metadata": {
        "id": "Lw8KUK079GDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), input_shape=(180,180,3), padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1,activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "JcrewY7x9IjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "epochs=1\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "dzOUuRi79KkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "szRkau1E9PBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation using tf.image"
      ],
      "metadata": {
        "id": "f8Jz2Nfk9W19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "metadata": {
        "id": "UlnJYGYZ9aGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(train_ds))\n",
        "plt.imshow(image)\n",
        "plt.title(get_label_name(label));"
      ],
      "metadata": {
        "id": "5_b11sFF9cb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(original, augmented):\n",
        "    fig = plt.figure()\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Original image')\n",
        "    plt.imshow(original)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('Augmented image')\n",
        "    plt.imshow(augmented)\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "x7DqDZju9egB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flipped = tf.image.flip_left_right(image)\n",
        "visualize(image, flipped)"
      ],
      "metadata": {
        "id": "RjkstqfC9gfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grayscaled = tf.image.rgb_to_grayscale(image)\n",
        "visualize(image,  tf.squeeze(grayscaled))"
      ],
      "metadata": {
        "id": "OHkTTX339jvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saturated = tf.image.adjust_saturation(image, 3)\n",
        "visualize(image, saturated)"
      ],
      "metadata": {
        "id": "yKZ0mjzf9kZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bright = tf.image.adjust_brightness(image, 0.4)\n",
        "visualize(image, bright)"
      ],
      "metadata": {
        "id": "FyMduI5Q9msk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropped = tf.image.central_crop(image, central_fraction=0.5)\n",
        "visualize(image, cropped)"
      ],
      "metadata": {
        "id": "YR8jyGvL9pHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rotated = tf.image.rot90(image)\n",
        "visualize(image, rotated)"
      ],
      "metadata": {
        "id": "fFiE_DR49rM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  seed = (i, 0)  # tuple of size (2,)\n",
        "  stateless_random_brightness = tf.image.stateless_random_brightness(\n",
        "      image, max_delta=0.95, seed=seed)\n",
        "  visualize(image, stateless_random_brightness)"
      ],
      "metadata": {
        "id": "H-1P2mjz9tDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "  image = (image / 255.0)\n",
        "  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])\n",
        "  image = tf.image.random_brightness(image, max_delta=0.5)\n",
        "  return image, label\n",
        "\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(1000)\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "WocJlpIh9v3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(x_train,y_train, batch_size=6):\n",
        "    for i in range(0, 6):\n",
        "        plt.subplot(2,3,i+1)\n",
        "        plt.imshow(X_batch[i]/255)\n",
        "        plt.axis('off')\n",
        "    break"
      ],
      "metadata": {
        "id": "Z4UtnEkX9yHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-kNmKmP91fD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}